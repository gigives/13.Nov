
Logging initialized using configuration in jar:file:/usr/lib/hive/lib/hive-common-1.1.0-cdh5.13.0.jar!/hive-log4j.properties
OK
Time taken: 2.693 seconds
Query ID = root_20201019153535_fa661ea4-065b-4df5-a0ef-9d3a21653169
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1603143438825_0083, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1603143438825_0083/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1603143438825_0083
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2020-10-19 15:35:49,413 Stage-1 map = 0%,  reduce = 0%
2020-10-19 15:36:00,783 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.01 sec
2020-10-19 15:36:11,587 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.49 sec
MapReduce Total cumulative CPU time: 4 seconds 490 msec
Ended Job = job_1603143438825_0083
Launching Job 2 out of 3
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1603143438825_0084, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1603143438825_0084/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1603143438825_0084
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2020-10-19 15:36:24,303 Stage-2 map = 0%,  reduce = 0%
2020-10-19 15:36:33,159 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.24 sec
2020-10-19 15:36:42,870 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.03 sec
MapReduce Total cumulative CPU time: 3 seconds 30 msec
Ended Job = job_1603143438825_0084
Launching Job 3 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1603143438825_0085, Tracking URL = http://quickstart.cloudera:8088/proxy/application_1603143438825_0085/
Kill Command = /usr/lib/hadoop/bin/hadoop job  -kill job_1603143438825_0085
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1
2020-10-19 15:36:55,599 Stage-3 map = 0%,  reduce = 0%
2020-10-19 15:37:04,363 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.14 sec
2020-10-19 15:37:15,094 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.75 sec
MapReduce Total cumulative CPU time: 2 seconds 750 msec
Ended Job = job_1603143438825_0085
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.49 sec   HDFS Read: 14320 HDFS Write: 96 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.03 sec   HDFS Read: 4442 HDFS Write: 96 SUCCESS
Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.75 sec   HDFS Read: 5426 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 10 seconds 270 msec
OK
Time taken: 102.755 seconds
WARN: The method class org.apache.commons.logging.impl.SLF4JLogFactory#release() was invoked.
WARN: Please see http://www.slf4j.org/codes.html#release for an explanation.
